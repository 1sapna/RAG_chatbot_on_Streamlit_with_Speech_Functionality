# app.py

#=================
# Import Libraries
#=================

import streamlit as st
import pandas as pd
import os
from langchain_experimental.agents.agent_toolkits.csv.base import create_csv_agent
from openai import OpenAI
from langchain.document_loaders import PyPDFLoader
from PyPDF2 import PdfReader
from langchain.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.chains.question_answering import load_qa_chain
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from langchain.agents import Tool
from langchain.embeddings import HuggingFaceEmbeddings
from io import BytesIO
from uuid import uuid4
from dotenv import load_dotenv

load_dotenv()  # get environment variables from .env file

#=================
# Background Image , Chatbot Title and Logo
#=================

page_bg_img = '''
<style>
.stApp  {
background-image: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url("https://imageio.forbes.com/specials-images/imageserve/6271151bcd7b0b7ffd1fa4e2/Artificial-intelligence-robot/960x0.jpg");
background-size: cover;
}
</style>
'''
st.markdown(page_bg_img, unsafe_allow_html=True)

st.title("Gen AI RAG Chatbot")
try:
    image_url = "logo-new.png"
    st.sidebar.image(image_url, caption="", use_column_width=True)
except:
    image_url = "https://static.vecteezy.com/system/resources/previews/010/794/341/non_2x/purple-artificial-intelligence-technology-circuit-file-free-png.png"
    st.sidebar.image(image_url, caption="", use_column_width=True)

#=================
# API Key and Files Upload
#=================

openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")
os.environ["OPENAI_API_KEY"] = openai_api_key

file_format = st.sidebar.selectbox("Select File Format", ["CSV", "PDF", "TXT"])
if file_format == "TXT":
    file_format = "plain"

uploaded_files = st.sidebar.file_uploader("Upload a file", type=["csv", "txt", "pdf"], accept_multiple_files=True)

def validateFormat(file_format, uploaded_files):
    """
    Checks if the format of uploaded files matches the selected format.

    Args:
        file_format (str): The selected file format (CSV, PDF, TXT).
        uploaded_files (list): A list of uploaded files.

    Returns:
        bool: True if all file formats match, False otherwise.
    """
    for file in uploaded_files:
        if str(file_format).lower() not in str(file.type).lower():
            return False
    return True

def save_uploadedfile(uploadedfile):
    """
    Saves the uploaded file to the current directory.

    Args:
        uploaded_file (streamlit.UploadedFile): The uploaded file object.

    Returns:
        str: A success message indicating the file has been saved.
    """
    with open(os.path.join(uploadedfile.name), "wb") as f:
        f.write(uploadedfile.getbuffer())
    return st.success("Saved File")

#=================
# Answer Generation Functions Based on Uploaded File Format
#=================

def history_func(answer, q):
    """
    Creates and manages the chat history in the Streamlit session state.

    Args:
        answer (str): The answer generated by the LLM.
        q (str): The user's question.
    """
    if 'history' not in st.session_state:
        st.session_state.history = ''

    value = f'Q: {q} \nA: {answer}'
    st.session_state.history = f'{value} \n {"-" * 100} \n {st.session_state.history}'
    h = st.session_state.history
    st.text_area(label='Chat History', value=h, key='history', height=400)

def CSVAnalysis(uploaded_file):
    """
    Performs analysis on a CSV file and allows users to ask questions.

    Args:
        uploaded_file (streamlit.UploadedFile): The uploaded CSV file.
    """
    df = pd.read_csv(uploaded_file)
    left_column, right_column = st.columns(2)
    with left_column:
        st.header("Dataframe Head")
        st.write(df.head())
    with right_column:
        st.header("Dataframe Tail")
        st.write(df.tail())
    save_uploadedfile(uploaded_file)
    fileName = uploaded_file.name
    user_query = st.text_input('Enter your query')
    agent = create_csv_agent(ChatOpenAI(temperature=0), fileName, verbose=True, max_iterations=100)

    if st.button("Answer My Question"):
        response = agent.run(user_query)
        st.text_area('LLM Answer: ', value=response, height=400)
        history_func(response, user_query)

def PDFAnalysis(uploaded_files, analysis_type="merge"):
    """
    Analyzes PDFs by merging or comparing.

    Args:
        uploaded_files (list): List of uploaded PDF files.
        analysis_type (str): Type of analysis ("merge" or "compare").
    """
    raw_text = ''
    for file in uploaded_files:
        pdf_reader = PdfReader(file)
        for page in pdf_reader.pages:
            text = page.extract_text()
            if text:
                raw_text += text

    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
    )
    texts = text_splitter.split_text(raw_text)

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-mpnet-base-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': False})

    docsearch = FAISS.from_texts(texts, embeddings)

    question = st.text_input("Enter your question")

    if st.button("Answer My Question"):
        docs = docsearch.similarity_search(question)
        chain = load_qa_chain(ChatOpenAI(temperature=0), chain_type="stuff")
        answer = chain.run(input_documents=docs, question=question)
        st.text_area('LLM Answer: ', value=answer, height=400)
        history_func(answer, question)

def TextAnalysis(uploaded_files):
    """
    Analyzes text files and allows users to ask questions.

    Args:
        uploaded_files (list): List of uploaded text files.
    """
    raw_text = ''
    for file in uploaded_files:
        temp_text = file.read().decode("utf-8")
        raw_text += temp_text

    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
    )
    texts = text_splitter.split_text(raw_text)

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-mpnet-base-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': False})

    docsearch = FAISS.from_texts(texts, embeddings)

    question = st.text_input("Enter your question")

    if st.button("Answer My Question"):
        docs = docsearch.similarity_search(question)
        chain = load_qa_chain(ChatOpenAI(temperature=0), chain_type="stuff")
        answer = chain.run(input_documents=docs, question=question)
        st.text_area('LLM Answer: ', value=answer, height=400)
        history_func(answer, question)

#=================
# Main Logic
#=================

if uploaded_files:
    if validateFormat(file_format, uploaded_files):
        if file_format == "CSV":
            if len(uploaded_files) > 1:
                st.write("Only 1 CSV file can be uploaded")
            else:
                for file in uploaded_files:
                    CSVAnalysis(file)
        elif file_format == "PDF":
            PDFAnalysis(uploaded_files)
        else:
            TextAnalysis(uploaded_files)
